/**
 * üîÑ BATCH PROCESSOR
 * Utilitaire pour traiter de grandes quantit√©s d'op√©rations IndexedDB
 * sans surcharger les transactions du navigateur
 */

import { logger } from './logger'

export interface BatchOptions {
  batchSize?: number
  onProgress?: (completed: number, total: number) => void
  onError?: (error: any, item: any, index: number) => void
  continueOnError?: boolean
}

/**
 * Traite un tableau d'items en batches pour √©viter la surcharge
 * des transactions IndexedDB (limite ~50 transactions simultan√©es)
 * 
 * @example
 * const results = await processBatch(
 *   items,
 *   async (item) => createCard(item),
 *   { batchSize: 50, onProgress: (done, total) => console.log(`${done}/${total}`) }
 * )
 */
export async function processBatch<T, R>(
  items: T[],
  processor: (item: T, index: number) => Promise<R>,
  options: BatchOptions = {}
): Promise<R[]> {
  const { 
    batchSize = 50, 
    onProgress, 
    onError,
    continueOnError = false
  } = options
  
  const results: R[] = []
  const errors: Array<{ index: number; error: any; item: T }> = []
  
  logger.info('BatchProcessor', `D√©marrage traitement de ${items.length} items par batches de ${batchSize}`)
  
  for (let i = 0; i < items.length; i += batchSize) {
    const batch = items.slice(i, Math.min(i + batchSize, items.length))
    const batchStartIndex = i
    
    try {
      const batchResults = await Promise.allSettled(
        batch.map((item, batchIndex) => 
          processor(item, batchStartIndex + batchIndex)
        )
      )
      
      // Traiter les r√©sultats du batch
      batchResults.forEach((result, batchIndex) => {
        const globalIndex = batchStartIndex + batchIndex
        
        if (result.status === 'fulfilled') {
          results.push(result.value)
        } else {
          const error = result.reason
          const item = batch[batchIndex]
          
          errors.push({ index: globalIndex, error, item })
          
          if (onError) {
            onError(error, item, globalIndex)
          } else {
            logger.error('BatchProcessor', `Erreur item ${globalIndex}`, { error, item })
          }
          
          if (!continueOnError) {
            throw new Error(`Batch processing failed at item ${globalIndex}: ${error.message}`)
          }
        }
      })
      
      onProgress?.(results.length, items.length)
      
      // Petite pause entre batches pour lib√©rer le thread et √©viter saturation
      if (i + batchSize < items.length) {
        await new Promise(resolve => setTimeout(resolve, 10))
      }
      
    } catch (error) {
      logger.error('BatchProcessor', `Erreur critique batch ${i}-${i + batch.length}`, { error })
      if (!continueOnError) {
        throw error
      }
    }
  }
  
  logger.info('BatchProcessor', `Traitement termin√©: ${results.length} succ√®s, ${errors.length} erreurs`)
  
  if (errors.length > 0 && !continueOnError) {
    throw new Error(`Batch processing completed with ${errors.length} errors`)
  }
  
  return results
}

/**
 * Version s√©quentielle pour op√©rations critiques n√©cessitant ordre strict
 * Plus lent mais garantit l'ordre et √©vite totalement les probl√®mes de concurrence
 * 
 * @example
 * const results = await processSequential(
 *   items,
 *   async (item, index) => createCardWithDependency(item, index)
 * )
 */
export async function processSequential<T, R>(
  items: T[],
  processor: (item: T, index: number) => Promise<R>,
  options: { 
    onProgress?: (completed: number, total: number) => void
    onError?: (error: any, item: any, index: number) => void
    continueOnError?: boolean
  } = {}
): Promise<R[]> {
  const { onProgress, onError, continueOnError = false } = options
  const results: R[] = []
  
  logger.info('BatchProcessor', `D√©marrage traitement s√©quentiel de ${items.length} items`)
  
  for (let i = 0; i < items.length; i++) {
    try {
      const result = await processor(items[i], i)
      results.push(result)
      onProgress?.(i + 1, items.length)
    } catch (error) {
      logger.error('BatchProcessor', `Erreur s√©quentielle item ${i}`, { error, item: items[i] })
      
      if (onError) {
        onError(error, items[i], i)
      }
      
      if (!continueOnError) {
        throw error
      }
    }
  }
  
  logger.info('BatchProcessor', `Traitement s√©quentiel termin√©: ${results.length}/${items.length} succ√®s`)
  
  return results
}

/**
 * Traite en chunks avec callback apr√®s chaque chunk
 * Utile pour UI updates ou op√©rations n√©cessitant feedback interm√©diaire
 */
export async function processChunks<T, R>(
  items: T[],
  processor: (chunk: T[], chunkIndex: number) => Promise<R[]>,
  options: {
    chunkSize?: number
    onChunkComplete?: (results: R[], chunkIndex: number, totalChunks: number) => void
  } = {}
): Promise<R[]> {
  const { chunkSize = 100, onChunkComplete } = options
  const allResults: R[] = []
  const totalChunks = Math.ceil(items.length / chunkSize)
  
  logger.info('BatchProcessor', `D√©marrage traitement par chunks: ${totalChunks} chunks de ${chunkSize}`)
  
  for (let i = 0; i < items.length; i += chunkSize) {
    const chunk = items.slice(i, Math.min(i + chunkSize, items.length))
    const chunkIndex = Math.floor(i / chunkSize)
    
    const chunkResults = await processor(chunk, chunkIndex)
    allResults.push(...chunkResults)
    
    onChunkComplete?.(chunkResults, chunkIndex, totalChunks)
    
    // Pause entre chunks
    if (i + chunkSize < items.length) {
      await new Promise(resolve => setTimeout(resolve, 5))
    }
  }
  
  logger.info('BatchProcessor', `Traitement chunks termin√©: ${allResults.length} r√©sultats`)
  
  return allResults
}
